{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43bf622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (145449, 5)\n",
      "\n",
      "Columns: ['id', 'verifiable', 'label', 'claim', 'evidence']\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "SUPPORTS           80035\n",
      "NOT ENOUGH INFO    35639\n",
      "REFUTES            29775\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample rows:\n",
      "                                               claim            label  \\\n",
      "0  Nikolaj Coster-Waldau worked with the Fox Broa...         SUPPORTS   \n",
      "1                 Roman Atwood is a content creator.         SUPPORTS   \n",
      "2  History of art includes architecture, dance, s...         SUPPORTS   \n",
      "3                  Adrienne Bailon is an accountant.          REFUTES   \n",
      "4       System of a Down briefly disbanded in limbo.  NOT ENOUGH INFO   \n",
      "\n",
      "       verifiable  \n",
      "0      VERIFIABLE  \n",
      "1      VERIFIABLE  \n",
      "2      VERIFIABLE  \n",
      "3      VERIFIABLE  \n",
      "4  NOT VERIFIABLE  \n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the FEVER dataset manually since the evidence field has mixed types\n",
    "data_path = Path('../data/fever.jsonl')\n",
    "fever_data = []\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        fever_data.append(json.loads(line))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(fever_data)\n",
    "\n",
    "# Print basic dataset info\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Display a few examples\n",
    "print(\"\\nSample rows:\")\n",
    "print(df[['claim', 'label', 'verifiable']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6522b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 145449\n",
      "Training rows: 116359\n",
      "Validation rows: 29090\n",
      "\n",
      "Training label distribution:\n",
      "label\n",
      "SUPPORTS           0.550263\n",
      "NOT ENOUGH INFO    0.245026\n",
      "REFUTES            0.204711\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation label distribution:\n",
      "label\n",
      "SUPPORTS           0.550258\n",
      "NOT ENOUGH INFO    0.245033\n",
      "REFUTES            0.204710\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We'll use an 80/20 split, as planned.\n",
    "# stratify=df['label'] is important for imbalanced datasets!\n",
    "# random_state=42 ensures you get the same \"random\" split every time.\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Training rows: {len(train_df)}\")\n",
    "print(f\"Validation rows: {len(val_df)}\")\n",
    "\n",
    "print(\"\\nTraining label distribution:\")\n",
    "print(train_df['label'].value_counts(normalize=True))\n",
    "print(\"\\nValidation label distribution:\")\n",
    "print(val_df['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3350d3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Training on 116359 examples.\n",
      "Validating on 29090 examples.\n",
      "\n",
      "Model pipeline created.\n",
      "\n",
      "Training the baseline model... (This may take 1-2 minutes)\n",
      "Training complete!\n",
      "\n",
      "Making predictions on the validation data...\n",
      "Training complete!\n",
      "\n",
      "Making predictions on the validation data...\n",
      "\n",
      "--- Week 1 Baseline Results ---\n",
      "Accuracy: 59.88%\n",
      "Macro-F1 Score: 0.4583\n",
      "---------------------------------\n",
      "\n",
      "--- Week 1 Baseline Results ---\n",
      "Accuracy: 59.88%\n",
      "Macro-F1 Score: 0.4583\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# --- 1. Data Preparation ---\n",
    "print(\"Preparing data...\")\n",
    "X_train = train_df['claim']\n",
    "y_train = train_df['label']\n",
    "    \n",
    "X_val = val_df['claim']\n",
    "y_val = val_df['label']\n",
    "\n",
    "print(f\"Training on {len(X_train)} examples.\")\n",
    "print(f\"Validating on {len(X_val)} examples.\")\n",
    "\n",
    "\n",
    "# --- 2. Model Pipeline ---\n",
    "# Step 1: The text-to-number converter\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english') \n",
    "# (stop_words='english' ignores common words like 'the', 'is', 'a')\n",
    "\n",
    "# Step 2: The classifier \"brain\"\n",
    "svm_classifier = LinearSVC(dual=True, max_iter=1000) \n",
    "\n",
    "# Create the pipeline that does Step 1 then Step 2\n",
    "model = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('clf', svm_classifier),\n",
    "])\n",
    "\n",
    "print(\"\\nModel pipeline created.\")\n",
    "\n",
    "\n",
    "# --- 3. Train the Model ---\n",
    "print(\"\\nTraining the baseline model... (This may take 1-2 minutes)\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "\n",
    "# --- 4. Evaluate the Model ---\n",
    "print(\"\\nMaking predictions on the validation data...\")\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate our scores\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
    "\n",
    "print(\"\\n--- Week 1 Baseline Results ---\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Macro-F1 Score: {macro_f1:.4f}\")\n",
    "print(\"---------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
